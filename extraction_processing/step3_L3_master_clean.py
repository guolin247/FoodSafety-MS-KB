import json
import pandas as pd
import datetime

# ================= ÈÖçÁΩÆÂå∫ =================
INPUT_FILE = r"D:\work_GuoLin\FoodSafety-MS-KB\FoodSafety_MS_L2_cleaned.json" # L2 Ê∏ÖÊ¥óÂêéÁöÑËæìÂÖ•
OUTPUT_JSON = "FoodSafety_MS_Master.json"
OUTPUT_CSV = "FoodSafety_MS_Master.csv"
LOG_FILE = "L3_cleaning_log.md"
# ========================================

class L3MasterCleaner:
    def __init__(self):
        # ÂÆö‰πâÈúÄË¶ÅË¢´‚ÄúÊèêÊãî‚Äù‰∏∫Áã¨Á´ãÂàóÁöÑ performance_parameters ÁöÑÈîÆÂêçÂêå‰πâËØç
        self.key_mappings = {
            'RT_min': ['rt', 'retention time', 'relative_retention_time', 'r.t.'],
            'LOQ': ['loq', 'limit of quantification', 'lod', 'detection_sensitivity', 'concentration'],
            'Matrix_Tag': ['context', 'matrix', 'solvent', 'group', 'source'],
            'DP_V': ['dp', 'declustering potential', 'cone voltage'],
            'EP_V': ['ep', 'entrance potential'],
            'CXP_V': ['cxp', 'collision cell exit potential'],
            'FV_V': ['fv', 'fragmentor voltage', 'in-source fragmentation voltage', 'source fragmentation voltage']
        }
        # ÊûÑÂª∫‰∏Ä‰∏™ÂèçÂêëÊü•ÊâæË°®ÔºåÁî®‰∫éËØÜÂà´Âì™‰∫õkeyÂ∑≤ÁªèË¢´ÊèêÊãî
        self.promoted_keys = {item for sublist in self.key_mappings.values() for item in sublist}
        
        # ÂÆö‰πâÈúÄË¶ÅÊ†áÂáÜÂåñÁöÑËØçÊ±áË°®
        self.type_map = {
            'quantification': 'Quant', 'quant': 'Quant', 'ÂÆöÈáè': 'Quant',
            'confirmation': 'Qual', 'qual': 'Qual', 'ÂÆöÊÄß': 'Qual'
        }
        self.pol_map = {
            'positive': 'Pos', 'pos': 'Pos', 'esi+': 'Pos', '+': 'Pos', 'Ê≠£': 'Pos',
            'negative': 'Neg', 'neg': 'Neg', 'esi-': 'Neg', '-': 'Neg', 'Ë¥ü': 'Neg'
        }

    def clean_ce(self, ce_raw):
        """Ê∏ÖÊ¥ó CEÔºåËøîÂõû (Value, Unit)"""
        val, unit = None, 'V'
        if isinstance(ce_raw, dict):
            val, unit = ce_raw.get('value'), ce_raw.get('unit', 'V')
        elif ce_raw is not None:
            val = ce_raw
        
        if val is not None:
            try:
                if str(val).lower() in ['m', 'l', 'h']:
                    return str(val).lower(), 'Category'
                val_str = str(val).lower().replace('ev', '').replace('v', '').strip()
                return float(val_str), 'V' if 'ev' in str(unit).lower() or 'v' in str(unit).lower() else unit
            except (ValueError, TypeError):
                return str(val), unit
        return None, None

    def process_records(self, l2_data):
        master_rows = []
        
        for rec in l2_data:
            # 1. ÊèêÂèñÂÖ¨ÂÖ±Â≠óÊÆµ
            common_info = {
                "Method_ID": rec.get("method_id"),
                "Run_ID": rec.get("run_config_id"),
                "Compound": rec.get("compound_english_name"),
                "CAS": rec.get("CAS_number"),
                "Source_File": rec.get("_source_file")
            }

            # 2. ÊèêÂèñÂπ∂ÂΩí‰∏ÄÂåñ Performance Parameters
            perfs = rec.get("performance_parameters", []) or []
            promoted_params = {}
            other_params = {}
            
            for p in perfs:
                p_name = str(p.get("parameter_name", "")).lower().strip()
                is_promoted = False
                # Ê£ÄÊü•ÊòØÂê¶ÊòØÈúÄË¶ÅÊèêÊãîÁöÑÂ≠óÊÆµ
                for target_col, synonyms in self.key_mappings.items():
                    if p_name in synonyms:
                        # Âè™ÂèñÁ¨¨‰∏Ä‰∏™ÊâæÂà∞ÁöÑÂÄºÔºåÈÅøÂÖçÈáçÂ§ç
                        if target_col not in promoted_params:
                            promoted_params[target_col] = p.get('value')
                        is_promoted = True
                        break
                
                # Â¶ÇÊûúÊ≤°ÊúâË¢´ÊèêÊãîÔºåÊîæÂÖ• Other_Params
                if not is_promoted:
                    val = p.get('value')
                    unit = p.get('unit')
                    full_val = f"{val} {unit}" if unit else str(val)
                    other_params[p.get("parameter_name")] = full_val

            # 3. ÁàÜÁÇ∏ MS Params
            ms_list = rec.get("mass_spec_params", []) or []
            if not ms_list: # Â¶ÇÊûúÊ≤°ÊúâÁ¶ªÂ≠êÂØπÔºåË∑≥ËøáÊ≠§ËÆ∞ÂΩï
                continue

            for ms in ms_list:
                row = {**common_info, **promoted_params} # ÂêàÂπ∂ÂÖ¨ÂÖ±‰ø°ÊÅØÂíåÊèêÊãîÁöÑÊÄßËÉΩÂèÇÊï∞
                
                # Â°´ÂÖÖË¥®Ë∞±‰ø°ÊÅØ
                row["Precursor_mz"] = ms.get("precursor_mz")
                row["Product_mz"] = ms.get("product_mz")
                
                # Ê∏ÖÊ¥ó Polarity
                raw_pol = str(ms.get("polarity", "")).lower()
                row["Polarity"] = next((v for k, v in self.pol_map.items() if k in raw_pol), "N/A") if raw_pol != 'none' else None

                # Ê∏ÖÊ¥ó Type
                raw_type = str(ms.get("parameter_type", "") or ms.get("source_ion_label", "")).lower()
                row["Type"] = next((v for k, v in self.type_map.items() if k in raw_type), "Target")
                
                # Ê∏ÖÊ¥ó CE
                row["CE_Value"], row["CE_Unit"] = self.clean_ce(ms.get("collision_energy"))
                
                # ‰øùÁïôÈïøÂ∞æÂèÇÊï∞
                row["Other_Params"] = json.dumps(other_params) if other_params else None
                
                master_rows.append(row)
                
        return master_rows

# ================= ÊâßË°å =================
if __name__ == "__main__":
    print("üöÄ Starting L3 Master Cleaning (Exploding, Normalizing, Preserving)...")
    
    cleaner = L3MasterCleaner()
    log = {}
    
    try:
        with open(INPUT_FILE, 'r', encoding='utf-8') as f:
            l2_data = json.load(f)
        log['input_records'] = len(l2_data)
            
        cleaned_rows = cleaner.process_records(l2_data)
        log['output_rows'] = len(cleaned_rows)
        
        # ‰øùÂ≠ò CSV (Êé®ËçêÁî®‰∫éÊï∞ÊçÆÈôÑ‰ª∂)
        df = pd.DataFrame(cleaned_rows)
        # ÈáçÊñ∞ÊéíÂ∫èÂàóÔºåËÆ©Ê†∏ÂøÉÂàóÂú®Ââç
        core_cols = ['Method_ID', 'Run_ID', 'Compound', 'CAS', 'Precursor_mz', 'Product_mz', 'Polarity', 'Type', 'CE_Value', 'RT_min', 'LOQ', 'Matrix_Tag']
        other_cols = [c for c in df.columns if c not in core_cols]
        df = df[core_cols + other_cols]
        df.to_csv(OUTPUT_CSV, index=False, encoding='utf-8-sig')
        print(f"‚úÖ CSV Saved: {OUTPUT_CSV} (Total Rows: {log['output_rows']})")
        
        # ‰øùÂ≠ò JSON (Áî®‰∫éWeb App)
        with open(OUTPUT_JSON, 'w', encoding='utf-8') as f:
            # Pandas to_json Êõ¥ÈÄÇÂêàÊâÅÂπ≥ÁªìÊûÑ
            df.to_json(f, orient='records', indent=2)
        print(f"‚úÖ JSON Saved: {OUTPUT_JSON}")
        
        # ‰øùÂ≠òÊó•Âøó
        log['explosion_ratio'] = log['output_rows'] / log['input_records'] if log['input_records'] > 0 else 0
        with open(LOG_FILE, 'w', encoding='utf-8') as f:
            f.write("# Master Dataset Build Log (L3)\n\n")
            f.write(f"**Date:** {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            f.write(f"- **Input L2 Records:** {log['input_records']}\n")
            f.write(f"- **Output Master Rows (Transitions):** {log['output_rows']}\n")
            f.write(f"- **Explosion Ratio:** {log['explosion_ratio']:.2f}x\n")
        print(f"üìù Log saved to {LOG_FILE}")
        
    except Exception as e:
        print(f"‚ùå Error during L3 cleaning: {e}")