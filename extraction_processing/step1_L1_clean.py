import json
import os
import datetime

# ================= é…ç½®åŒº =================
INPUT_FOLDER = r"D:\work_GuoLin\FoodSafety-MS-KB\extraction_processing\raw_data"
OUTPUT_FILE = "FoodSafety_MS_Raw_v1.json"
LOG_FILE = "L1_cleaning_log.md"
# ========================================

class AuditLogger:
    def __init__(self):
        self.logs = []
        self.stats = {
            "total_files": 0,
            "total_input_records": 0,
            "total_output_records": 0,
            "dropped_records": [],
            "structure_fixes": [],
            "string_cleanups": 0
        }

    def log_structure_fix(self, filename, original_type):
        self.stats["structure_fixes"].append(f"File **{filename}** converted from `{original_type}` to `List`.")

    def log_dropped(self, filename, index, reason, snippet):
        self.stats["dropped_records"].append({
            "file": filename,
            "index": index,
            "reason": reason,
            "snippet": str(snippet)[:100] + "..." # åªè®°å½•å‰100ä¸ªå­—ç¬¦ç”¨äºæ ¸å¯¹
        })

    def increment_string_clean(self):
        self.stats["string_cleanups"] += 1

    def save_report(self, filepath):
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(f"# Data Cleaning Audit Log (L1)\n")
            f.write(f"**Date:** {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("## 1. Summary Statistics\n")
            f.write(f"- **Files Processed:** {self.stats['total_files']}\n")
            f.write(f"- **Total Input Records:** {self.stats['total_input_records']}\n")
            f.write(f"- **Total Valid Output:** {self.stats['total_output_records']}\n")
            f.write(f"- **Dropped Records:** {len(self.stats['dropped_records'])}\n")
            f.write(f"- **String Format Fixes (whitespace/newlines):** {self.stats['string_cleanups']}\n\n")
            
            f.write("## 2. Structure Normalization\n")
            if self.stats["structure_fixes"]:
                for fix in self.stats["structure_fixes"]:
                    f.write(f"- {fix}\n")
            else:
                f.write("- No structural anomalies found.\n")
            
            f.write("\n## 3. Dropped Records Detail\n")
            if self.stats["dropped_records"]:
                f.write("| File | Index | Reason | Snippet |\n")
                f.write("|---|---|---|---|\n")
                for item in self.stats["dropped_records"]:
                    f.write(f"| {item['file']} | {item['index']} | {item['reason']} | `{item['snippet']}` |\n")
            else:
                f.write("- No records were dropped.\n")
                
        print(f"ğŸ“ Audit log saved to {filepath}")

auditor = AuditLogger()

def clean_string_with_audit(val):
    """é€’å½’æ¸…æ´—å­—ç¬¦ä¸²ï¼Œå¹¶è®¡æ•°"""
    if isinstance(val, str):
        # æ£€æŸ¥æ˜¯å¦æœ‰éœ€è¦æ¸…æ´—çš„å†…å®¹
        cleaned = val.strip().replace('\n', ' ').replace('\t', ' ')
        if cleaned != val:
            auditor.increment_string_clean()
        return cleaned
    elif isinstance(val, list):
        return [clean_string_with_audit(x) for x in val]
    elif isinstance(val, dict):
        return {k: clean_string_with_audit(v) for k, v in val.items()}
    else:
        return val

def process_l1_cleaning():
    print(f"ğŸ§¹ Re-running L1 Cleaning with Audit...")
    
    all_records = []
    
    if not os.path.exists(INPUT_FOLDER):
        print("âŒ Input folder not found.")
        return

    for filename in os.listdir(INPUT_FOLDER):
        if not filename.endswith(".json"): continue
        
        filepath = os.path.join(INPUT_FOLDER, filename)
        auditor.stats["total_files"] += 1
        
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                raw = json.load(f)
            
            # 1. ç»“æ„è¯Šæ–­ä¸ä¿®å¤
            current_batch = []
            if isinstance(raw, list):
                current_batch = raw
            elif isinstance(raw, dict):
                auditor.log_structure_fix(filename, "Dict")
                if "detections" in raw:
                    current_batch = raw["detections"]
                else:
                    current_batch = [raw]
            
            auditor.stats["total_input_records"] += len(current_batch)
            
            # 2. é€æ¡æ¸…æ´—
            for idx, rec in enumerate(current_batch):
                # 2.1 å®Œæ•´æ€§æ£€æŸ¥
                ms_params = rec.get("mass_spec_params")
                if not ms_params or (isinstance(ms_params, list) and len(ms_params) == 0):
                    # è®°å½•ä¸¢å¼ƒåŸå› 
                    compound_name = rec.get("compound_english_name", "Unknown")
                    auditor.log_dropped(filename, idx, "Empty/Missing MS Params", f"Compound: {compound_name}")
                    continue
                
                # 2.2 å­—ç¬¦ä¸²å‡€åŒ–
                cleaned_rec = clean_string_with_audit(rec)
                
                # 2.3 æ³¨å…¥æ¥æº
                cleaned_rec["_source_file"] = filename
                
                all_records.append(cleaned_rec)
                
        except Exception as e:
            print(f"  âŒ Error processing {filename}: {e}")

    auditor.stats["total_output_records"] = len(all_records)

    # 3. ä¿å­˜æ•°æ®
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(all_records, f, ensure_ascii=False, indent=2)
    
    # 4. ä¿å­˜æ—¥å¿—
    auditor.save_report(LOG_FILE)
    print(f"ğŸ’¾ Data saved to {OUTPUT_FILE}")

if __name__ == "__main__":
    process_l1_cleaning()