import json
import pandas as pd
import random
import os

# ================= é…ç½®åŒº =================
# è¯·æ›¿æ¢ä¸ºæ‚¨çš„ detections.json æ–‡ä»¶çš„ç»å¯¹è·¯å¾„
# è¿™é‡Œå‡è®¾è¾“å…¥çš„æ˜¯æ¸…æ´—åçš„æœ€ç»ˆç‰ˆæœ¬
INPUT_FILE = r"D:\work_GuoLin\FoodSafety-MS-KB\data\detections.json"
OUTPUT_EXCEL = "Detections_Audit_Sampling_350.xlsx"
SAMPLE_SIZE = 350
# ========================================

def generate_detection_sample():
    print(f"ğŸš€ Starting Detection Sampling (Target: {SAMPLE_SIZE} records)...")
    
    if not os.path.exists(INPUT_FILE):
        print(f"âŒ Error: Input file not found at {INPUT_FILE}")
        return

    try:
        with open(INPUT_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
        # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœæ ¹èŠ‚ç‚¹æ˜¯ list åˆ™ç›´æ¥ç”¨ï¼Œå¦‚æœæ˜¯ dict åˆ™æ‰¾ keys
        all_records = data if isinstance(data, list) else data.get("detections", [])
        
        total_records = len(all_records)
        print(f"ğŸ“Š Total Records Loaded: {total_records}")
        
        if total_records < SAMPLE_SIZE:
            print(f"âš ï¸ Warning: Total records ({total_records}) < Sample Size ({SAMPLE_SIZE}). Taking all.")
            sample_size = total_records
        else:
            sample_size = SAMPLE_SIZE

    except Exception as e:
        print(f"âŒ Error loading JSON: {e}")
        return

    # --- ç­–ç•¥ï¼šå±•å¼€æ‰€æœ‰ç¦»å­å¯¹ (Flattening) ---
    # å› ä¸ºä¸€æ¡ detection è®°å½•é‡Œå¯èƒ½æœ‰å¤šä¸ª mass_spec_params (å¤šå¯¹ç¦»å­)
    # æ‚¨çš„è¦æ±‚æ˜¯â€œä¸€ç§åŒ–åˆç‰©å¯¹åº”çš„ä¸€ä¸ªç¦»å­å¯¹çš„æ•°æ®â€ä½œä¸ºä¸€æ¡æŠ½æ ·å•ä½ã€‚
    # å¦‚æœæ‚¨çš„ JSON ç»“æ„æ˜¯ï¼šä¸€æ¡è®°å½• = ä¸€ä¸ªåŒ–åˆç‰© = åŒ…å« mass_spec_params æ•°ç»„ (å« Q, q1, q2...)
    # é‚£ä¹ˆæˆ‘ä»¬éœ€è¦å…ˆâ€œå±•å¼€â€è¿™ä¸ªæ•°ç»„ï¼ŒæŠŠæ¯ä¸€å¯¹ (Precursor, Product) å˜æˆä¸€ä¸ªå¯æŠ½æ ·çš„ Itemã€‚
    
    flattened_items = []
    
    for parent_idx, rec in enumerate(all_records):
        method_id = rec.get("method_id", "Unknown")
        run_id = rec.get("run_config_id", "Unknown")
        comp_name = rec.get("compound_english_name", "Unknown")
        cas = rec.get("CAS_number", "Unknown")
        source_file = rec.get("_source_file", "Unknown") # ç”¨äºæº¯æº
        
        ms_params = rec.get("mass_spec_params", [])
        if not isinstance(ms_params, list): continue
        
        for sub_idx, ms in enumerate(ms_params):
            # æå–å…³é”®æ•°å€¼
            prec_mz = ms.get("precursor_mz")
            prod_mz = ms.get("product_mz")
            # --- ä¿®æ­£å¼€å§‹: å®‰å…¨è·å– Collision Energy ---
            ce_obj = ms.get("collision_energy")
            if isinstance(ce_obj, dict):
                ce = ce_obj.get("value")
            else:
                ce = None # æˆ–è€… "N/A" å¦‚æœæ‚¨å¸Œæœ›åœ¨è¡¨æ ¼é‡Œæ˜¾ç¤ºå­—ç¬¦
            # --- ä¿®æ­£ç»“æŸ ---
            pol = ms.get("polarity")
            p_type = ms.get("parameter_type") # Quant/Conf
            
            # æ„å»ºæ‰å¹³åŒ–å¯¹è±¡
            item = {
                "Parent_Index": parent_idx, # æ–¹ä¾¿å›æº¯
                "Sub_Index": sub_idx,
                "Method_ID": method_id,
                "Run_ID": run_id,
                "Compound_Name": comp_name,
                "CAS": cas,
                "Precursor_m/z": prec_mz,
                "Product_m/z": prod_mz,
                "Collision_Energy": ce,
                "Polarity": pol,
                "Type": p_type,
                "Source_File": source_file
            }
            flattened_items.append(item)
            
    print(f"   -> Flattened into {len(flattened_items)} unique transitions (ion pairs).")

    # --- æŠ½æ ·ç­–ç•¥ï¼šåˆ†å±‚æŠ½æ · (Stratified by Method ID) ---
    # ç›®çš„ï¼šä¿è¯æ¯ä¸ª Method è‡³å°‘è¢«æŠ½åˆ°ä¸€ç‚¹ï¼Œå¤§ Method æŠ½å¤šç‚¹ã€‚
    
    df_pool = pd.DataFrame(flattened_items)
    
    # æŒ‰ Method_ID åˆ†ç»„æŠ½æ ·
    # è®¡ç®—æ¯ä¸ª Method çš„æƒé‡
    # å¦‚æœ Method æ•°é‡å¤ªå¤šï¼Œå¯¼è‡´ sample_size ä¸å¤Ÿåˆ†ï¼Œåˆ™é€€åŒ–ä¸ºéšæœºæŠ½æ ·
    
    try:
        # ä½¿ç”¨ pandas çš„ groupby sample (éœ€ pandas >= 1.1.0)
        # weights è®¾ä¸º None è¡¨ç¤ºæŒ‰æ¯”ä¾‹è‡ªç„¶åˆ†å±‚
        # frac = sample_size / total
        fraction = sample_size / len(df_pool)
        
        # ä¸ºäº†ä¿è¯ç²¾ç¡®å‡‘å¤Ÿ 350 æ¡ï¼Œç®€å•åˆ†å±‚æœ‰æ—¶ä¼šæœ‰å–èˆè¯¯å·®ã€‚
        # è¿™é‡Œé‡‡ç”¨æ›´ç¨³å¥çš„æ–¹æ³•ï¼šç›´æ¥ä»æ•´ä½“æ± å­é‡Œå¸¦æƒé‡éšæœºæŠ½æ ·ï¼ˆæƒé‡=1ï¼Œå³ç®€å•éšæœºï¼‰ï¼Œ
        # æˆ–è€…å…ˆæŒ‰ Method_ID åˆ†ç»„ï¼Œæ¯ç»„è‡³å°‘æŠ½ 1 æ¡ï¼Œå‰©ä¸‹çš„éšæœºåˆ†ã€‚
        
        # ç®€åŒ–ç­–ç•¥ï¼šç›´æ¥ç®€å•éšæœºæŠ½æ · (Simple Random Sampling) 
        # å› ä¸ºç¦»å­å¯¹æ€»æ•°å¤§ï¼ŒéšæœºæŠ½æ ·é€šå¸¸èƒ½å¾ˆå¥½åœ°è¦†ç›–å„å¤§ Methodã€‚
        # å¦‚æœæ‚¨ä¸€å®šè¦ä¸¥æ ¼åˆ†å±‚ï¼Œè¯·å‘Šè¯‰æˆ‘ã€‚æ­¤å¤„ä½¿ç”¨ Random ä»¥ä¿è¯æ“ä½œç®€ä¾¿ä¸”ç»Ÿè®¡å­¦æœ‰æ•ˆã€‚
        
        sampled_df = df_pool.sample(n=sample_size, random_state=42) # è®¾å®šç§å­ä¿è¯å¯å¤ç°
        
    except Exception as e:
        print(f"âš ï¸ Sampling error: {e}. Falling back to head.")
        sampled_df = df_pool.head(sample_size)

    # --- æ ¼å¼åŒ–è¾“å‡º ---
    # å¢åŠ æ’åºåˆ—ï¼Œæ–¹ä¾¿æ‚¨æ ¸å¯¹ï¼ˆä¾‹å¦‚æŒ‰ Method ID æ’åºï¼‰
    sampled_df = sampled_df.sort_values(by=["Method_ID", "Compound_Name"])
    
    # å¢åŠ äººå·¥æ‰“åˆ†åˆ—
    sampled_df["[Check] Precursor Correct?"] = ""
    sampled_df["[Check] Product Correct?"] = ""
    sampled_df["[Check] CE Correct?"] = ""
    sampled_df["[Check] Meta Correct? (Name/CAS)"] = ""
    sampled_df["Auditor_Comments"] = ""

    # è°ƒæ•´åˆ—é¡ºåº
    cols = [
        "Method_ID", "Run_ID", "Compound_Name", "CAS", 
        "Precursor_m/z", "[Check] Precursor Correct?",
        "Product_m/z", "[Check] Product Correct?",
        "Collision_Energy", "[Check] CE Correct?",
        "Polarity", "Type", 
        "[Check] Meta Correct? (Name/CAS)", "Auditor_Comments",
        "Source_File", "Parent_Index", "Sub_Index"
    ]
    
    # åªä¿ç•™å­˜åœ¨çš„åˆ—
    cols = [c for c in cols if c in sampled_df.columns]
    final_df = sampled_df[cols]

    # ä¿å­˜
    try:
        writer = pd.ExcelWriter(OUTPUT_EXCEL, engine='xlsxwriter')
        final_df.to_excel(writer, index=False, sheet_name='Detection_Audit')
        
        workbook = writer.book
        worksheet = writer.sheets['Detection_Audit']
        
        # æ ¼å¼
        header_fmt = workbook.add_format({'bold': True, 'bg_color': '#D9D9D9', 'border': 1})
        check_fmt = workbook.add_format({'bg_color': '#FFF2CC', 'border': 1}) # é»„è‰²èƒŒæ™¯æç¤ºå¡«ç©º
        
        for col_num, value in enumerate(final_df.columns.values):
            worksheet.write(0, col_num, value, header_fmt)
            
            # å¦‚æœæ˜¯ Check åˆ—ï¼ŒåŠ å®½å¹¶æ ‡é»„
            if "[Check]" in value:
                worksheet.set_column(col_num, col_num, 15, check_fmt)
            else:
                worksheet.set_column(col_num, col_num, 15)
                
        writer.close()
        print(f"âœ… Sampling Complete. Checklist saved to: {OUTPUT_EXCEL}")
        print(f"   Please open the file and verify {len(final_df)} records against your PDFs.")
        
    except Exception as e:
        print(f"âŒ Error saving Excel: {e}")

if __name__ == "__main__":
    generate_detection_sample()